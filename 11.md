# Metrics Server

### 简述

Metrics Server（指标服务器）是一个应用于集群中的资源指标的聚合器。通过Metrics Server，可以方便地使用kubectl top命令查看pods和nodes的CPU和Memory的使用情况。由于使用Kubeadm工具搭建了Kubernetes集群，所以默认情况下并没有安装Metrics Server，因此需要手动安装。

### 下载部署文件

因为安装的Kubernetes版本为v1.11.3，所以到Github上获取Kubernetes对应版本下的<a href="https://github.com/kubernetes/kubernetes/tree/v1.11.3/cluster/addons/metrics-server"><font color="blue">Metrics Server部署文件</font></a>。

注意，有必要阅读Kubernetes仓库目录`kubernetes/cluster/addons/metrics-server/`下的`README.md`文件。
修改部署文件

**1：修改resource-reader.yaml文件，在如下图位置的`resources`下添加一行配置`- nodes/stats`。**

<pre>
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:metrics-server
  labels:
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  - namespaces
  - <font color="red">nodes/stats</font>
  verbs:
......
</pre>

**2：修改metrics-server-deployment.yaml文件（需要修改三个地方）。**

由于该文件配置了Kubernetes的deployment对象，其中指定了两个需要翻墙的镜像，若服务器不能翻墙，则可以将对应镜像修改如下：

<pre>
k8s.gcr.io/metrics-server-amd64:v0.2.1  -> <font color="red">registry.cn-qingdao.aliyuncs.com/dlchenmr/metrics-server-amd64:v0.2.1</font>
k8s.gcr.io/addon-resizer:1.8.1  -> <font color="red">registry.cn-qingdao.aliyuncs.com/dlchenmr/addon-resizer:1.8.1</font>
</pre>

最后，需要修改该文件中容器名为metrics-server对应command中的Flag，修改如下:

<pre>
--source=kubernetes.summary_api:''  -> <font color="red">--source=kubernetes.summary_api:https://kubernetes.default?kubeletHttps=true&kubeletPort=10250&insecure=true</font>
</pre>

修改过的文件如下图所示（截取部分内容）：

<pre>
......
      containers:
      - name: metrics-server
        image: <font color="red">registry.cn-qingdao.aliyuncs.com/dlchenmr/metrics-server-amd64:v0.2.1</font>
        command:
        - /metrics-server
        - <font color="red">--source=kubernetes.summary_api:https://kubernetes.default?kubeletHttps=true&kubeletPort=10250&insecure=true</font>
        ports:
        - containerPort: 443
          name: https
          protocol: TCP
      - name: metrics-server-nanny
        image: <font color="red">registry.cn-qingdao.aliyuncs.com/dlchenmr/addon-resizer:1.8.1</font>
        resources:
......
</pre>

镜像addon-resizer的作用是垂直伸缩其监视的容器（这里为metrics-server），更多详情参阅<a href="https://github.com/kubernetes/autoscaler/tree/master/addon-resizer"><font color="blue">addon-resizer介绍</font></a>。

注意，metrics-server抓取指标的间隔时间默认是`60s`，可以通过`--metric-resolution=<duration>`指定间隔时间（记得加单位，如：120s）。若想了解更多关于metrics-server的Flag，可以到对应的容器内部，执行命令`/metrics-server --help`查看。

### 部署Metrics Server

在集群服务器上创建`metrics-server`目录，并将相关的安装文件放置该目录下，最后执行以下命令安装Metrics Server：

```
kubectl apply -f metrics-server/
```

Metrics Server会被部署在kube-system命令空间下，可以通过以下命令查看容器是否已经正常Running：

```
kubectl get pods -n kube-system | grep metrics
```

### 检测能否正常使用

经过上述安装并Running后，还需要等待Metrics Server正常工作（可能1~3 min，一般不会超过5 min，超过说明很可能出现了异常，需要自己着手排查）。

Metrics Server正常工作后，通过后就可以查看pods和nodes的CPU和Memory的使用情况了。例如：

**1：查看pods**

```
# kubectl top pods
NAME                     CPU(cores)   MEMORY(bytes)   
nginx-5fb84b5976-xg9n5   0m           1Mi 
```

**2：查看nodes**

```
# kubectl top nodes
NAME        CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%         
master1     260m         8%        4053Mi          71%       
master2     169m         5%        3172Mi          55%       
master3     146m         4%        2912Mi          51%       
worker01      158m         3%        10322Mi         65%       
worker02      169m         4%        10033Mi         66%       
......
```

### 接下来

更多详情可以查阅官方文档<a href="https://v1-11.docs.kubernetes.io/docs/tasks/debug-application-cluster/core-metrics-pipeline/"><font color="blue">core-metrics-pipeline</font></a>。

# Horizontal Pod Autoscaler

### 简述

Horizontal Pod Autoscaler（<b>HPA</b>，水平Pod自动伸缩器）可以根据观察到CPU利用率（或者其它应用提供的指标）自动伸缩replication controller（RC），deployment或replica set的Pod数量。

### 前提条件

在使用Horizontal Pod Autoscaler前，要求Kubernetes集群和kubectl的版本为1.2或之后，此外还需要安装本文前面所述的Metrics Server（或者heapster，但在Kubernetes v1.11后被弃用）。

### 开始前
当通过kubectl autoscale命令创建HPA对象时，其默认的YAML文件的apiVersion值为autoscaling/v1，并能根据CPU利用率伸缩Pod数量。若想根据其它指标伸缩Pod，则需要定义apiVersion为autoscaling/v2beta1的YAML文件。

本部分内容介绍使用autoscaling/v1根据CPU伸缩Pod数量。

### 使用HPA

**1：部署NGINX作为测试的对象**

创建nginx.yaml文件，其内容如下：

<pre>
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
        <font color="red">resources:
          requests:
            cpu: 200m</font>
---
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    name: nginx
spec:
  ports:
    - port: 80
  selector:
    app: nginx
</pre>

注意，需要设置容器的resources.request.cpu，否则HPA不能正常工作。

执行以下命令部署nginx：

```
kubectl apply -f nginx.yaml
```

**2：为NGINX创建HPA对象**

创建hpa-nginx.yaml文件，其内容如下：

<pre>
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx
spec:
  <font color="red">scaleTargetRef:</font>
    apiVersion: extensions/v1beta1
    kind: Deployment
    name: nginx
  <font color="red">minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 5</font>
</pre>

**说明：**

`scaleTargetRef`：指定需要自动伸缩的对象。

`minReplicas`：最小的POD副本数量。

`maxReplicas`：最大的POD副本数量。

`targetCPUUtilizationPercentage`：目标CPU利用率百分比（这里指`5%`）。

执行以下命令为nginx创建hpa对象：
```
kubectl apply -f hpa-nginx.yaml
```

创建完成后，过一会查看nginx的hpa对象：

```
# kubectl get hpa nginx
NAME      REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
nginx     Deployment/nginx   0%/5%    1         10        1          2m
```

**部分字段说明：**

`TARGETS`：值`0%/5%`表示当前CPU利用率为`0%`，而用户定义的CPU利用率为`5%`。

`MINPODS`：POD的最小数量。

`MAXPODS`：POD的最大数量。

`REPLICAS`：当前POD数量。

**3：增加NGINX的负载**

由于现在NGINX的CPU利用率为`0%`，所以看不到什么效果。所以接下来可以通过增加NGNX的负载来观察伸缩效果。

启动一个busybox容器：

```
# kubectl run -i --tty load-generator --image=busybox /bin/sh
If you don't see a command prompt, try pressing enter.
```

等到控制台输出以上提示内容时，就可以在busybox容器中输入命令了。现在需要做的是，向nginx循环地发送请求以增加其负载，命令如下：
```
while true; do wget -q -O- http://nginx.default.svc.cluster.local; done
```

接下来，再打开一个新的终端窗口，查看NGINX的HPA对象，可能会看到类似以下内容 ：

```
# kubectl get hpa
NAME      REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
nginx     Deployment/nginx   17%/5%    1         10        3          18m
```

这里的REPLICAS字段值变成了`3`。注意，POD的伸缩并非实时的，需要经过一定的时间才能使REPLICAS趋于稳定，本文后续会说明。通过命令查看NGINX的POD数量是否为`3`：

```
# kubectl get pods | grep  nginx
nginx-6b95bb4754-bkkts            1/1       Running   0          1h
nginx-6b95bb4754-vm8fx            1/1       Running   0          4m
nginx-6b95bb4754-jgfb9            1/1       Running   0          3m
```

也可以通过以下命令查看NGINX的相关信息：

```
# kubectl get deployment nginx
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     3         3         3            3           1h
```

以上结果表明HPA有起作用。

**4：减少NGINX的负载**

结束前面循环请求NGINX的进程（`Ctrl + C`），过一段时间再次查看NGINX的HPA，会有类似以下信息：

```
# kubectl get hpa nginx
NAME      REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
nginx     Deployment/nginx   0%/5%    1         10        1          1h
```

NGINX当前CPU利用率为0%，REPLICAS对应值为`1`。再次查看POD，发现数量已经为`1`：

```
# kubectl get pods | grep  nginx
nginx-6b95bb4754-bkkts            1/1       Running   0          1h
```

**5：自动伸缩算法**

伸缩POD数量的计算公式为：
<pre>
TargetNumOfPods = <b>ceil</b>(<b>sum</b>(CurrentPodsCPUUtilization) / Target)
</pre>

**上述公式含义说明：**

* `TargetNumOfPods`：POD的数量。
* `CurrentPodsCPUUtilization`：现有POD的CPU利用率。其计算试为：POD最近1分钟CPU使用率的平均值`除以`POD设置`resources.requests.cpu`的值。
* `Target`：HPA对象中配置的`targetCPUUtilizationPercentage`的值。
* `sum(CurrentPodsCPUUtilization)`：不同POD的`CurrentPodsCPUUtilization`的总和。
* `ceil(...)`：对计算的值向上取整。如计算结果为5.1，则向上取整后为`6`。

<br/>
启动和停止PODs时可能会为指标带来“噪音”（例如，启动可能会临时地增加CPU）。因此，在后续的每个操作，Autoscaler应该等待一些时间以获取可靠的数据。对于“扩容”而言，仅会在距上次“扩容”的3 分钟之后才会发生。对于“缩容”而言，仅会在距上次“缩容”的5 分钟之后才会发生。此外，任何伸缩只会在`avg(CurrentPodsConsumption) / Target`的计算值低于`0.9`或者高于`1.1`（`10%`的公差）时发生。这样做有两个好处：

* Autoscaler以一种保守的方式工作。如果出现了新的用户负载，则应该快速地增加PODs数量，避免请求不会被拒绝。而减少PODs数量的行为并不那么急迫。（为什么“扩容”的间隔时间小于“缩容”的间隔时间）。
* Autoscaler避免负载不稳定时带来的系统“波动”。

<br/>
通过上面描述可知Autoscaler不会对POD进行实时的水平伸缩。可以通过设置kube-controller-manager组件的命令参数来调整（通过修改位于Master节点`/etc/kubernetes/manifests/`目录下的`kube-controller-manager.yaml`文件）：

* `--horizontal-pod-autoscaler-sync-period=<duration>`：指定轮询获取POD资源信息的时间，默认为`30s`。
* `--horizontal-pod-autoscaler-downscale-delay=<duration>`：相邻两次“缩容”的间隔时间，默认为`5m0s`。
* `--horizontal-pod-autoscaler-upscale-delay=<duration>`：相邻两次“扩容”的间隔时间，默认为`3m0s`。
* `--horizontal-pod-autoscaler-tolerance=<float>`：设置自动伸缩所允许的公差，默认为`0.1`（即`10%`）。

有关自动伸缩的算法，可以查阅官方原文<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/autoscaling/horizontal-pod-autoscaler.md#autoscaling-algorithm"><font color="blue">autoscaling-algorithm</font></a>。

### 接下来

更多详情可以查阅官方文档<a href="https://v1-11.docs.kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"><font color="blue">horizontal-pod-autoscale</font></a>，<a href="https://v1-11.docs.kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/"><font color="blue">horizontal-pod-autoscale-walkthrough</font></a>。

# 文中超链接

<pre>

<font color="blue">Metrics Server部署文件</font> -> https://github.com/kubernetes/kubernetes/tree/v1.11.3/cluster/addons/metrics-server

<font color="blue">core-metrics-pipelinev</font> -> https://v1-11.docs.kubernetes.io/docs/tasks/debug-application-cluster/core-metrics-pipeline/

<font color="blue">addon-resizer介绍</font> -> https://github.com/kubernetes/autoscaler/tree/master/addon-resizer

<font color="blue">horizontal-pod-autoscale</font> -> https://v1-11.docs.kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/

<font color="blue">horizontal-pod-autoscale-walkthrough</font> -> https://v1-11.docs.kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/

<font color="blue">autoscaling-algorithm</font> -> https://github.com/kubernetes/community/blob/master/contributors/design-proposals/autoscaling/horizontal-pod-autoscaler.md#autoscaling-algorithm

</pre>

